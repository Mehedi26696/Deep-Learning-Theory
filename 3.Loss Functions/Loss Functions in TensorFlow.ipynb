{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "007bf9b6-e8cd-4465-a092-bb60b4aec1b8",
   "metadata": {},
   "source": [
    "<center><h1 style=\"color:green\">Loss Functions in TensorFlow</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf5214f-eb70-4c0d-acbd-c05c25e8d680",
   "metadata": {},
   "source": [
    "#### **1. What is a Loss Function?**\n",
    "A loss function is used to measure how well a model's predictions match the true data. It computes the difference between the predicted and actual values and guides the optimization process during training.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Types of Loss Functions**\n",
    "\n",
    "##### **A. Regression Losses**\n",
    "1. **Mean Squared Error (MSE)**\n",
    "   - Formula: $$ L = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 $$\n",
    "   - Penalizes large errors more heavily.\n",
    "   - Use Case: Regression problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa929f95-5239-49f8-be89-da4e850f1c6a",
   "metadata": {},
   "source": [
    "2. **Mean Absolute Error (MAE)**\n",
    "   - Formula: $$ L = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i| $$\n",
    "   - Less sensitive to outliers than MSE.\n",
    "   - Use Case: Regression problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed64d4c2-434a-4a90-a8a5-c2aacf2bdf6c",
   "metadata": {},
   "source": [
    "\n",
    "3. **Huber Loss**\n",
    "   - Combines MSE and MAE to be less sensitive to outliers.\n",
    "   - Use Case: Regression with some outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bde90fa-6f94-49e2-a81e-cf73f0fa639e",
   "metadata": {},
   "source": [
    "##### **B. Classification Losses**\n",
    "1. **Binary Crossentropy**\n",
    "   - Formula: $$ L = -\\frac{1}{n} \\sum_{i=1}^{n} [y_i \\log(\\hat{y}_i) + (1-y_i) \\log(1-\\hat{y}_i)] $$\n",
    "   - For binary classification tasks.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed84538-5bcc-43fb-ace1-0d5890360113",
   "metadata": {},
   "source": [
    "2. **Categorical Crossentropy**\n",
    "   - Formula: $$ L = -\\sum_{i=1}^{n} y_i \\log(\\hat{y}_i) $$\n",
    "   - For multi-class classification with one-hot encoded labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8962b90-e25f-46e9-8046-e7886e6784d0",
   "metadata": {},
   "source": [
    "3. **Sparse Categorical Crossentropy**\n",
    "   - Similar to Categorical Crossentropy but works with integer labels instead of one-hot encoding.\n",
    "   - Use Case: Multi-class classification with sparse labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf3fb6a-099c-462d-ae88-a8d49c5c9143",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### **3. Key Features of TensorFlow Loss Functions**\n",
    "- **Reduction Parameter**: Controls how the loss is reduced (e.g., sum, mean, or none).\n",
    "  ```python\n",
    "  loss = tf.keras.losses.BinaryCrossentropy(reduction=tf.keras.losses.Reduction.SUM)\n",
    "  ```\n",
    "- **From_logits Parameter**: Use when predictions are raw logits instead of probabilities.\n",
    "  ```python\n",
    "  loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. Choosing the Right Loss Function**\n",
    "- **Regression**: Use MSE, MAE, or Huber Loss.\n",
    "- **Binary Classification**: Use Binary Crossentropy.\n",
    "- **Multi-Class Classification**: Use Categorical Crossentropy or Sparse Categorical Crossentropy.\n",
    "- **Custom Scenarios**: Define a custom loss function based on the problem.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
